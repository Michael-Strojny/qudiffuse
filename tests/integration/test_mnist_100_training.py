#!/usr/bin/env python3
"""
QuDiffuse MNIST-100 Training Test

This script tests the complete QuDiffuse image generation system on 100 MNIST images.
ZERO mocks, ZERO simplifications, ZERO placeholders - full authentic system on small dataset.

Purpose: Verify that the complete QuDiffuse system works end-to-end with real training.
"""

import os
import sys
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Subset
import torchvision
import torchvision.transforms as transforms
import logging
import time
from tqdm import tqdm
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

# Add paths for QuDiffuse imports
sys.path.append('src')
from qudiffuse.models.multi_resolution_binary_ae import MultiResolutionBinaryAutoEncoder
from qudiffuse.models.dbn import HierarchicalDBN
from qudiffuse.models.binary_latent_manager import BinaryLatentManager
from qudiffuse.models.timestep_specific_dbn_manager import TimestepSpecificDBNManager
from qudiffuse.diffusion.timestep_specific_binary_diffusion import TimestepSpecificBinaryDiffusion
from qudiffuse.diffusion.schedule import BernoulliSchedule
from qudiffuse.diffusion.unified_reverse_process import UnifiedReverseProcess, SamplingMode, ClassicalFallbackMode
from qudiffuse.utils.common_utils import ensure_device_consistency, cleanup_gpu_memory

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class QuDiffuseMNISTConfig:
    """Configuration for MNIST training (small scale but authentic)."""
    
    # Dataset settings
    dataset_size = 100  # Only 100 MNIST images
    batch_size = 8      # Small batch for testing
    image_size = 32     # Resize MNIST to 32x32
    
    # Model architecture (smaller but authentic)
    in_channels = 1     # MNIST grayscale
    latent_dims = [2]           # Single level: 2*16*16 = 512 bits = 0.5 BPP exactly
    target_resolutions = [16]     # Single spatial resolution
    codebook_sizes = [128]      # Single codebook
    
    # Training settings
    autoencoder_epochs = 5    # Small for testing
    diffusion_epochs = 3      # Small for testing
    learning_rate = 1e-4
    
    # Diffusion settings
    num_timesteps = 50        # Reduced for testing
    beta_start = 0.0001
    beta_end = 0.02
    
    # DBN settings
    dbn_hidden_sizes = [64, 32]  # Smaller for testing
    dbn_cd_steps = 5             # Reduced for testing
    
    # Device
    device = "cuda" if torch.cuda.is_available() else "cpu"


class MNIST100Trainer:
    """Complete QuDiffuse trainer for 100 MNIST images."""
    
    def __init__(self, config: QuDiffuseMNISTConfig):
        self.config = config
        self.device = torch.device(config.device)
        
        # Create output directories
        self.output_dir = "results/mnist_100_test"
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(f"{self.output_dir}/checkpoints", exist_ok=True)
        os.makedirs(f"{self.output_dir}/samples", exist_ok=True)
        
        logger.info(f"üöÄ Initializing MNIST-100 QuDiffuse training on {self.device}")
        
        # Setup data
        self.setup_data()
        
        # Setup models
        self.setup_models()
        
        # Setup training
        self.setup_training()
        
        logger.info("‚úÖ MNIST-100 QuDiffuse trainer initialized")
    
    def setup_data(self):
        """Setup MNIST dataset limited to 100 images."""
        logger.info("üìö Setting up MNIST-100 dataset...")
        
        # MNIST transforms
        transform = transforms.Compose([
            transforms.Resize(self.config.image_size),
            transforms.ToTensor(),
            transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]
        ])
        
        # Load full MNIST dataset
        full_dataset = torchvision.datasets.MNIST(
            root='./data', 
            train=True, 
            download=True, 
            transform=transform
        )
        
        # Take only first 100 images (authentic subset)
        indices = list(range(self.config.dataset_size))
        self.dataset = Subset(full_dataset, indices)
        
        # Train/val split (80/20 of 100 images)
        train_size = 80
        val_size = 20
        train_indices = indices[:train_size]
        val_indices = indices[train_size:train_size + val_size]
        
        self.train_dataset = Subset(full_dataset, train_indices)
        self.val_dataset = Subset(full_dataset, val_indices)
        
        # Data loaders
        self.train_loader = DataLoader(
            self.train_dataset,
            batch_size=self.config.batch_size,
            shuffle=True,
            num_workers=0,  # No multiprocessing for small dataset
            pin_memory=torch.cuda.is_available()
        )
        
        self.val_loader = DataLoader(
            self.val_dataset,
            batch_size=self.config.batch_size,
            shuffle=False,
            num_workers=0,
            pin_memory=torch.cuda.is_available()
        )
        
        logger.info(f"   Training samples: {len(self.train_dataset)}")
        logger.info(f"   Validation samples: {len(self.val_dataset)}")
        logger.info(f"   Batch size: {self.config.batch_size}")
    
    def setup_models(self):
        """Setup all QuDiffuse model components (authentic, no simplifications)."""
        logger.info("üèóÔ∏è Setting up QuDiffuse model components...")
        
        # 1. Multi-resolution binary autoencoder
        logger.info("   üì¶ Initializing Multi-Resolution Binary Autoencoder...")
        self.autoencoder = MultiResolutionBinaryAutoEncoder(
            in_channels=self.config.in_channels,
            resolution=self.config.image_size,
            latent_dims=self.config.latent_dims,
            target_resolutions=self.config.target_resolutions,
            codebook_sizes=self.config.codebook_sizes,
            deterministic=False  # Stochastic for training
        ).to(self.device)
        
        # 2. Binary latent manager
        logger.info("   üîÑ Initializing Binary Latent Manager...")
        self.binary_latent_manager = BinaryLatentManager(
            topology_type="hierarchical",
            storage_format="float32_binary",
            latent_shapes=[(dim, res, res) 
                            for dim, res in zip(self.config.latent_dims, self.config.target_resolutions)],
            device=str(self.device)
        )
        
        # 3. Noise schedule
        logger.info("   üìÖ Setting up noise schedule...")
        betas = np.linspace(
            self.config.beta_start, 
            self.config.beta_end, 
            self.config.num_timesteps
        )
        self.schedule = BernoulliSchedule(betas.tolist())
        
        # 4. Timestep-specific DBN manager
        logger.info("   üß† Initializing Timestep-Specific DBN Manager...")
        # Calculate total latent variables for DBN
        total_latent_vars = sum(
            dim * res * res 
            for dim, res in zip(self.config.latent_dims, self.config.target_resolutions)
        )
        
        self.timestep_dbn_manager = TimestepSpecificDBNManager(
            latent_shapes=[(dim, res, res) 
                          for dim, res in zip(self.config.latent_dims, self.config.target_resolutions)],
            hidden_dims=self.config.dbn_hidden_sizes,
            timesteps=self.config.num_timesteps,
            device=str(self.device)
        )
        
        # 5. Binary diffusion process
        logger.info("   üî• Initializing Binary Diffusion Process...")
        self.diffusion = TimestepSpecificBinaryDiffusion(
            timestep_dbn_manager=self.timestep_dbn_manager,
            binary_latent_manager=self.binary_latent_manager,
            betas=betas.tolist(),
            device=str(self.device)
        )
        
        # 6. Unified reverse process (with quantum/classical support)
        logger.info("   ‚ö° Initializing Unified Reverse Process...")
        self.reverse_process = UnifiedReverseProcess(
            timestep_dbn_manager=self.timestep_dbn_manager,
            binary_latent_manager=self.binary_latent_manager,
            betas=betas.tolist(),
            device=str(self.device),
            default_mode=SamplingMode.CLASSICAL_CD,  # Use classical for testing
            classical_fallback_mode=ClassicalFallbackMode.CONTRASTIVE_DIVERGENCE
        )
        
        # Count parameters
        ae_params = sum(p.numel() for p in self.autoencoder.parameters())
        logger.info(f"   üìä Autoencoder parameters: {ae_params:,}")
        logger.info(f"   üìä Total latent variables per sample: {total_latent_vars}")
        logger.info(f"   üìä Number of timesteps: {self.config.num_timesteps}")
    
    def setup_training(self):
        """Setup optimizers and training utilities."""
        logger.info("‚öôÔ∏è Setting up training utilities...")
        
        # Autoencoder optimizer
        self.ae_optimizer = optim.Adam(
            self.autoencoder.parameters(),
            lr=self.config.learning_rate,
            betas=(0.5, 0.999)
        )
        
        # Training metrics
        self.training_stats = {
            'ae_losses': [],
            'ae_reconstruction_losses': [],
            'ae_codebook_losses': [],
            'diffusion_losses': [],
            'training_times': []
        }
    
    def train_autoencoder_epoch(self, epoch: int):
        """Train autoencoder for one epoch."""
        self.autoencoder.train()
        epoch_ae_loss = 0.0
        epoch_recon_loss = 0.0
        epoch_codebook_loss = 0.0
        
        pbar = tqdm(self.train_loader, desc=f"Autoencoder Epoch {epoch+1}")
        
        for batch_idx, (images, _) in enumerate(pbar):
            images = images.to(self.device)
            
            # Forward pass
            self.ae_optimizer.zero_grad()
            
            # Autoencoder forward
            reconstruction, codebook_loss, stats = self.autoencoder(images)
            
            # Compute losses
            recon_loss = nn.MSELoss()(reconstruction, images)
            total_loss = recon_loss + 0.25 * codebook_loss
            
            # Backward pass
            total_loss.backward()
            torch.nn.utils.clip_grad_norm_(self.autoencoder.parameters(), 1.0)
            self.ae_optimizer.step()
            
            # Update metrics
            epoch_ae_loss += total_loss.item()
            epoch_recon_loss += recon_loss.item()
            epoch_codebook_loss += codebook_loss.item()
            
            # Update progress bar
            pbar.set_postfix({
                'Total': f'{total_loss.item():.4f}',
                'Recon': f'{recon_loss.item():.4f}',
                'Code': f'{codebook_loss.item():.4f}'
            })
        
        # Average losses
        avg_ae_loss = epoch_ae_loss / len(self.train_loader)
        avg_recon_loss = epoch_recon_loss / len(self.train_loader)
        avg_codebook_loss = epoch_codebook_loss / len(self.train_loader)
        
        # Store metrics
        self.training_stats['ae_losses'].append(avg_ae_loss)
        self.training_stats['ae_reconstruction_losses'].append(avg_recon_loss)
        self.training_stats['ae_codebook_losses'].append(avg_codebook_loss)
        
        logger.info(f"Autoencoder Epoch {epoch+1}: Loss={avg_ae_loss:.4f}, "
                   f"Recon={avg_recon_loss:.4f}, Codebook={avg_codebook_loss:.4f}")
        
        return avg_ae_loss
    
    def train_diffusion_epoch(self, epoch: int):
        """Train diffusion DBNs for one epoch."""
        epoch_diff_loss = 0.0
        
        pbar = tqdm(self.train_loader, desc=f"Diffusion Epoch {epoch+1}")
        
        for batch_idx, (images, _) in enumerate(pbar):
            images = images.to(self.device)
            
            # Get binary latents from autoencoder
            with torch.no_grad():
                binary_codes = self.autoencoder(images, code_only=True)
            
            # Train DBNs for multiple timesteps
            timestep_losses = []
            
            # Sample random timesteps for training
            timesteps = torch.randint(1, self.config.num_timesteps + 1, (len(images),))
            
            for i, t in enumerate(timesteps):
                t = t.item()
                
                # Get binary latent for this sample
                if isinstance(binary_codes, list):
                    sample_latent = [codes[i:i+1] for codes in binary_codes]
                else:
                    sample_latent = binary_codes[i:i+1]
                
                # Apply forward diffusion
                noisy_latent = self.diffusion.forward_process(sample_latent, t)
                
                # Train DBN for this timestep
                dbn = self.timestep_dbn_manager.get_or_create_dbn(t)
                
                # Convert latents to flat representation for DBN
                if isinstance(noisy_latent, list):
                    flat_noisy = torch.cat([z.flatten(1) for z in noisy_latent], dim=1)
                    flat_clean = torch.cat([z.flatten(1) for z in sample_latent], dim=1)
                else:
                    flat_noisy = noisy_latent.flatten(1)
                    flat_clean = sample_latent.flatten(1)
                
                # Train DBN with contrastive divergence
                if hasattr(dbn.rbms[0], 'train_step'):
                    dbn_optimizer = optim.SGD(dbn.parameters(), lr=0.01)
                    loss, _ = dbn.rbms[0].train_step(
                        flat_noisy, 
                        dbn_optimizer, 
                        k=self.config.dbn_cd_steps
                    )
                    timestep_losses.append(loss)
            
            avg_timestep_loss = np.mean(timestep_losses) if timestep_losses else 0.0
            epoch_diff_loss += avg_timestep_loss
            
            pbar.set_postfix({'DBN Loss': f'{avg_timestep_loss:.4f}'})
        
        avg_diff_loss = epoch_diff_loss / len(self.train_loader)
        self.training_stats['diffusion_losses'].append(avg_diff_loss)
        
        logger.info(f"Diffusion Epoch {epoch+1}: DBN Loss={avg_diff_loss:.4f}")
        
        return avg_diff_loss
    
    def validate(self):
        """Validate the model and generate samples."""
        logger.info("üîç Running validation...")
        
        self.autoencoder.eval()
        val_recon_loss = 0.0
        
        with torch.no_grad():
            for images, _ in self.val_loader:
                images = images.to(self.device)
                reconstruction, _, _ = self.autoencoder(images)
                recon_loss = nn.MSELoss()(reconstruction, images)
                val_recon_loss += recon_loss.item()
        
        avg_val_loss = val_recon_loss / len(self.val_loader)
        logger.info(f"Validation reconstruction loss: {avg_val_loss:.4f}")
        
        return avg_val_loss
    
    def generate_samples(self, num_samples: int = 4):
        """Generate samples using the complete diffusion process."""
        logger.info(f"üé® Generating {num_samples} samples...")
        
        self.autoencoder.eval()
        
        with torch.no_grad():
            # Generate binary latents through reverse diffusion
            latent_shape = [(self.config.latent_dims[0], self.config.target_resolutions[0], self.config.target_resolutions[0])]
            
            # Sample from noise
            generated_latents = self.diffusion.sample(latent_shape, num_samples)
            
            # Decode to images
            if isinstance(generated_latents, list):
                # For hierarchical latents, use the autoencoder's reconstruction
                images = self.autoencoder(codes=generated_latents)[0]
            else:
                images = self.autoencoder(codes=[generated_latents])[0]
            
            # Denormalize images
            images = (images + 1) / 2  # From [-1, 1] to [0, 1]
            images = torch.clamp(images, 0, 1)
        
        return images
    
    def save_samples(self, samples: torch.Tensor, filename: str):
        """Save generated samples to disk."""
        samples_np = samples.cpu().numpy()
        
        fig, axes = plt.subplots(1, len(samples_np), figsize=(2*len(samples_np), 2))
        if len(samples_np) == 1:
            axes = [axes]
        
        for i, sample in enumerate(samples_np):
            axes[i].imshow(sample[0], cmap='gray')
            axes[i].axis('off')
            axes[i].set_title(f'Sample {i+1}')
        
        plt.tight_layout()
        plt.savefig(f"{self.output_dir}/samples/{filename}")
        plt.close()
        
        logger.info(f"Saved samples to {filename}")
    
    def save_checkpoint(self, epoch: int, loss: float):
        """Save model checkpoint."""
        checkpoint = {
            'epoch': epoch,
            'autoencoder_state_dict': self.autoencoder.state_dict(),
            'optimizer_state_dict': self.ae_optimizer.state_dict(),
            'loss': loss,
            'config': self.config,
            'training_stats': self.training_stats
        }
        
        checkpoint_path = f"{self.output_dir}/checkpoints/checkpoint_epoch_{epoch}.pt"
        torch.save(checkpoint, checkpoint_path)
        logger.info(f"Checkpoint saved: {checkpoint_path}")
    
    def train_complete_system(self):
        """Train the complete QuDiffuse system."""
        logger.info("üöÄ Starting complete QuDiffuse training on MNIST-100...")
        start_time = time.time()
        
        # Stage 1: Train autoencoder
        logger.info("üì¶ Stage 1: Training Binary Autoencoder...")
        best_ae_loss = float('inf')
        
        for epoch in range(self.config.autoencoder_epochs):
            ae_loss = self.train_autoencoder_epoch(epoch)
            val_loss = self.validate()
            
            # Save checkpoint if best
            if ae_loss < best_ae_loss:
                best_ae_loss = ae_loss
                self.save_checkpoint(epoch, ae_loss)
            
            # Generate samples
            if epoch % 2 == 0:
                samples = self.generate_samples(4)
                self.save_samples(samples, f"ae_epoch_{epoch}_samples.png")
        
        logger.info(f"‚úÖ Autoencoder training complete. Best loss: {best_ae_loss:.4f}")
        
        # Stage 2: Train diffusion DBNs
        logger.info("üî• Stage 2: Training Diffusion DBNs...")
        
        for epoch in range(self.config.diffusion_epochs):
            diff_loss = self.train_diffusion_epoch(epoch)
            
            # Generate diffusion samples
            if epoch == self.config.diffusion_epochs - 1:
                samples = self.generate_samples(4)
                self.save_samples(samples, f"diffusion_epoch_{epoch}_samples.png")
        
        logger.info("‚úÖ Diffusion training complete!")
        
        # Final validation and sample generation
        final_val_loss = self.validate()
        final_samples = self.generate_samples(8)
        self.save_samples(final_samples, "final_samples.png")
        
        # Training summary
        total_time = time.time() - start_time
        logger.info("üéâ MNIST-100 QuDiffuse training completed!")
        logger.info(f"   Total training time: {total_time:.2f} seconds")
        logger.info(f"   Final validation loss: {final_val_loss:.4f}")
        logger.info(f"   Best autoencoder loss: {best_ae_loss:.4f}")
        logger.info(f"   Output directory: {self.output_dir}")
        
        return {
            'total_time': total_time,
            'final_val_loss': final_val_loss,
            'best_ae_loss': best_ae_loss,
            'training_stats': self.training_stats
        }


def main():
    """Main function to run MNIST-100 training test."""
    logger.info("üéØ QuDiffuse MNIST-100 Training Test")
    logger.info("ZERO mocks, ZERO simplifications, ZERO placeholders")
    logger.info("Testing complete authentic QuDiffuse system on small dataset")
    
    # Initialize configuration
    config = QuDiffuseMNISTConfig()
    
    # Log configuration
    logger.info("üìã Training Configuration:")
    logger.info(f"   Dataset size: {config.dataset_size} MNIST images")
    logger.info(f"   Batch size: {config.batch_size}")
    logger.info(f"   Image size: {config.image_size}x{config.image_size}")
    logger.info(f"   Autoencoder epochs: {config.autoencoder_epochs}")
    logger.info(f"   Diffusion epochs: {config.diffusion_epochs}")
    logger.info(f"   Timesteps: {config.num_timesteps}")
    logger.info(f"   Device: {config.device}")
    
    # Initialize trainer
    trainer = MNIST100Trainer(config)
    
    # Run training
    results = trainer.train_complete_system()
    
    # Report results
    logger.info("üìä Training Results Summary:")
    logger.info(f"   ‚úÖ Training completed successfully")
    logger.info(f"   ‚è±Ô∏è Total time: {results['total_time']:.2f}s")
    logger.info(f"   üìâ Final validation loss: {results['final_val_loss']:.4f}")
    logger.info(f"   üìà Best autoencoder loss: {results['best_ae_loss']:.4f}")
    logger.info(f"   üé® Sample images saved in: results/mnist_100_test/samples/")
    
    logger.info("üéâ MNIST-100 test completed - QuDiffuse system verified working!")
    
    return results


if __name__ == "__main__":
    results = main() 